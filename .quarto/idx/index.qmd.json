{"title":"hierarchy","markdown":{"yaml":{"title":"hierarchy","author":"Kiran Gauthier","listing":{"contents":"posts","sort":"date desc","type":"default","categories":true,"sort-ui":false,"filter-ui":false},"page-layout":"full","title-block-banner":true},"headingText":"`hierarchy`","containsRefs":false,"markdown":"\n\n\nWelcome to `hierarchy`, a blog about using regression, causal inference, machine learning, and hierarchical (multilevel) modeling to distinguish signal from noise. More broadly, we're going to use [computational statistics](https://en.wikipedia.org/wiki/Computational_statistics) to:\n1. measure unknowns\n2. think generatively\n3. quantify \"luck\" and \"surprise\"\n4. visualize and communicate the implications of our model & inference\n\nI, [Kiran](https://www.linkedin.com/in/kiran-gauthier/) , did my PhD in the [Bishop Group](https://bishop.cheme.columbia.edu/) at Columbia University, graduating in August 2022, where I defended my thesis on *optimal experimental design for hierarchical, nonlinear systems* for characterization and design of autonomous microrobots. You can find it [here](https://clio.columbia.edu/catalog/16899459?counter=1). My goal was to use external fields (think magnetic, acoustic) to encode behaviours into microscale colloids to help them autonomously sense their environment, and accomplish tasks in noisy environments. multimodality\n\nI started thinking about the *value* of data early on in grad school, because my experiments took a long time to run and a lot of them gave me useless results. As an added complication, my setup varied slightly every day, so I had to constantly recalibrate my understanding of the underlying parameters of my system. That led me to thinking about [experimental design](https://en.wikipedia.org/wiki/Design_of_experiments) to suggest maximally informative experiments conditional on the data that I've already observed. I highly recommend [this](https://arxiv.org/pdf/astro-ph/0409386.pdf) excellent paper from Tom Loredo which got me started about thinking in terms of probabilities and distributions, and how we quantify information using [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)). See the section on [experimental design](#experimental-design) for more info.\n\n\n**Why do I believe in statistical modeling:** [Chris Rackauckas](https://chrisrackauckas.com/) said in a [talk](https://youtu.be/bBH8HVEr0-A?si=_MHPc_CgPE9knED8&t=55) that \"the major advances in machine learning were due to encoding more structure into the model\" with a subquote of \"MORE STRUCTURE = FASTER AND BETTER FITS FROM LESS DATA\" and that sums it up pretty well. I think that building models that more closely resemble the \"true\" data generating process are our best hope of actually learning what's going on under the hood. And although it's fun to throw compute at a problem, I believe in [failing](https://stat.columbia.edu/~gelman/research/unpublished/Bayesian_Workflow_article.pdf) [fast](https://www.youtube.com/watch?v=ppKpwtGy8KQ) and in the power of the iterative model building [workflow](https://arxiv.org/pdf/2011.01808.pdf) using fast, and often approximate inference.\n\nUltimately, our models are only ever an approximation of reality, summarized perfectly by George Box when he said [\"all models are wrong, but some are useful\"](https://en.wikipedia.org/wiki/All_models_are_wrong). Our goal is then to find a model, $M$,\n\n![Coarse graining the true data-generating process](assets/1_BayesianDesign.png){.center} .\n\n\n\nfolk theorem of statistical computation\n\nintersection of what cna be done and what should be done, is the juice worth the squeeze\n\ndistinguish signal from noise\n\nhierarcchal models are everywhere\n\nastronomy (not astrology, I checked), psychology, psychometrics, ecology, econometrics,\n\n### Experimental design\n\nOther great papers to use as introductory material to experimental design are Huan and Marzouk's [paper](https://arxiv.org/pdf/1108.4146.pdf), Dennis Lindley's entire catalog, but [this](https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-27/issue-4/On-a-Measure-of-the-Information-Provided-by-an-Experiment/10.1214/aoms/1177728069.full) paper in particular, and Andrew Gelman's entire catalog, footnotes, and [this](http://www.stat.columbia.edu/~gelman/research/published/27.pdf) paper. Why his footnotes? I can't find the quote now (if you remember it, [email](mailto:kiran.gauthier@columbia.edu) me!) but it went something along the lines of \"every original thought you've ever had about statistics has already been published by Andrew [Gelman] in a footnote of a paper from the 1970s\".\n\nI'm [Kiran](https://scholar.google.com/citations?user=LEl-9SsAAAAJ&hl=en&oi=ao) and I'm a computational statistician, graduating with my PhD from Columbia University  other topics to figure out *if the juice is worth the squeeze*. I'll be programming in Python, R, Stan, and Julia, and am a huge advocate of failing fast, model parsimony, and [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor), so we'll be timing, multiprocessing, broadcasting, and using whichever backend can get us a close-enough answer fastest.\n\nI did my PhD in the Bishop group .............................. I wrote my dissertation using PyMC3 (now PyMC), and have recently switched to Stan because I've been writing in R a lot more. This blog will also give me a chance to revisit PyMC, Pyro and NumPyro (built on top of PyTorch), TFP (built on top of TensorFlow), and Turing.jl to see which is fast and readable.\n\nI also think that visualization is a huge part of my [workflow](https://arxiv.org/abs/2011.01808), which is why I've been super impressed with the ease-of-use of the [brms](https://cran.r-project.org/web/packages/brms/index.html) package (not to mention Paul's support on GitHub and the Stan Discourse), because getting inferential models to act generatively is pretty clunky and requires custom code to develop good visuals. brms takes care of this for you. To my knowledge, there's no Python equivalent so we'll flip back and forth depending on how far we are in the prototyping stage.\n\nMy favourite book right now is Richard McElreath's [\"Statistical Rethinking\"](https://xcelab.net/rm/statistical-rethinking/), and his accompanying [YouTube](https://www.youtube.com/watch?v=FdnMWdICdRs&list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus) series which are both incredibly well written / produced, and are great discussions of challenges with asking the \"oracle\" of regression seemingly innocuous questions (see the height ~ $alpha$ + $\\beta_{\\text{left leg}}$ $\\text{left leg})$ + $\\beta_{\\text{right leg}}$ $\\text{right leg}$ model for a great example).\n\nI believe that there's huge value in modeling data hierarchially, where groups of individuals are drawn from a population and we'd like to have information flow between them, but these models are often slow, [hard](https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html) to fit, and are usually much harder to set up than conventional non-hierarchical models. I'm hoping to have a repository that acts as a bridge between the different languages, and packages, so that we can all benefit from the massive amount of documentation and knowledge that has already been shared.\n\nI may make errors, if you see one, please email [kiran.gauthier@columbia.edu](mailto:kiran.gauthier@columbia.edu) me or leave a comment and I'll revise it!\n\n## Library\n\nI'll fill this later.\n\n### Other blogs I read\n\nGelman\nBetancourt\nFrank Harrell\nAki Vehtari\n\n### Posts to come\n\nBridgeStan\nSimpson's paradox\nBonferroni correction\nTalking about interactions\n\nWish list item: see how information flows between parameters, include something about synthetic data generation.\n\nAdd draft: true to the document options if youâ€™d like a post to not be included in the listing, site map, or site search. For example:\n#---\ntitle: \"My Post\"\ndescription: \"Post description\"\nauthor: \"Fizz McPhee\"\ndate: \"5/22/2021\"\ndraft: true\n#---\n\n## fill out the about.qmd next with a photo\n\ndate-modified: \"5/23/2021\"\n","srcMarkdownNoYaml":"\n\n## `hierarchy`\n\nWelcome to `hierarchy`, a blog about using regression, causal inference, machine learning, and hierarchical (multilevel) modeling to distinguish signal from noise. More broadly, we're going to use [computational statistics](https://en.wikipedia.org/wiki/Computational_statistics) to:\n1. measure unknowns\n2. think generatively\n3. quantify \"luck\" and \"surprise\"\n4. visualize and communicate the implications of our model & inference\n\nI, [Kiran](https://www.linkedin.com/in/kiran-gauthier/) , did my PhD in the [Bishop Group](https://bishop.cheme.columbia.edu/) at Columbia University, graduating in August 2022, where I defended my thesis on *optimal experimental design for hierarchical, nonlinear systems* for characterization and design of autonomous microrobots. You can find it [here](https://clio.columbia.edu/catalog/16899459?counter=1). My goal was to use external fields (think magnetic, acoustic) to encode behaviours into microscale colloids to help them autonomously sense their environment, and accomplish tasks in noisy environments. multimodality\n\nI started thinking about the *value* of data early on in grad school, because my experiments took a long time to run and a lot of them gave me useless results. As an added complication, my setup varied slightly every day, so I had to constantly recalibrate my understanding of the underlying parameters of my system. That led me to thinking about [experimental design](https://en.wikipedia.org/wiki/Design_of_experiments) to suggest maximally informative experiments conditional on the data that I've already observed. I highly recommend [this](https://arxiv.org/pdf/astro-ph/0409386.pdf) excellent paper from Tom Loredo which got me started about thinking in terms of probabilities and distributions, and how we quantify information using [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)). See the section on [experimental design](#experimental-design) for more info.\n\n\n**Why do I believe in statistical modeling:** [Chris Rackauckas](https://chrisrackauckas.com/) said in a [talk](https://youtu.be/bBH8HVEr0-A?si=_MHPc_CgPE9knED8&t=55) that \"the major advances in machine learning were due to encoding more structure into the model\" with a subquote of \"MORE STRUCTURE = FASTER AND BETTER FITS FROM LESS DATA\" and that sums it up pretty well. I think that building models that more closely resemble the \"true\" data generating process are our best hope of actually learning what's going on under the hood. And although it's fun to throw compute at a problem, I believe in [failing](https://stat.columbia.edu/~gelman/research/unpublished/Bayesian_Workflow_article.pdf) [fast](https://www.youtube.com/watch?v=ppKpwtGy8KQ) and in the power of the iterative model building [workflow](https://arxiv.org/pdf/2011.01808.pdf) using fast, and often approximate inference.\n\nUltimately, our models are only ever an approximation of reality, summarized perfectly by George Box when he said [\"all models are wrong, but some are useful\"](https://en.wikipedia.org/wiki/All_models_are_wrong). Our goal is then to find a model, $M$,\n\n![Coarse graining the true data-generating process](assets/1_BayesianDesign.png){.center} .\n\n\n\nfolk theorem of statistical computation\n\nintersection of what cna be done and what should be done, is the juice worth the squeeze\n\ndistinguish signal from noise\n\nhierarcchal models are everywhere\n\nastronomy (not astrology, I checked), psychology, psychometrics, ecology, econometrics,\n\n### Experimental design\n\nOther great papers to use as introductory material to experimental design are Huan and Marzouk's [paper](https://arxiv.org/pdf/1108.4146.pdf), Dennis Lindley's entire catalog, but [this](https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-27/issue-4/On-a-Measure-of-the-Information-Provided-by-an-Experiment/10.1214/aoms/1177728069.full) paper in particular, and Andrew Gelman's entire catalog, footnotes, and [this](http://www.stat.columbia.edu/~gelman/research/published/27.pdf) paper. Why his footnotes? I can't find the quote now (if you remember it, [email](mailto:kiran.gauthier@columbia.edu) me!) but it went something along the lines of \"every original thought you've ever had about statistics has already been published by Andrew [Gelman] in a footnote of a paper from the 1970s\".\n\nI'm [Kiran](https://scholar.google.com/citations?user=LEl-9SsAAAAJ&hl=en&oi=ao) and I'm a computational statistician, graduating with my PhD from Columbia University  other topics to figure out *if the juice is worth the squeeze*. I'll be programming in Python, R, Stan, and Julia, and am a huge advocate of failing fast, model parsimony, and [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor), so we'll be timing, multiprocessing, broadcasting, and using whichever backend can get us a close-enough answer fastest.\n\nI did my PhD in the Bishop group .............................. I wrote my dissertation using PyMC3 (now PyMC), and have recently switched to Stan because I've been writing in R a lot more. This blog will also give me a chance to revisit PyMC, Pyro and NumPyro (built on top of PyTorch), TFP (built on top of TensorFlow), and Turing.jl to see which is fast and readable.\n\nI also think that visualization is a huge part of my [workflow](https://arxiv.org/abs/2011.01808), which is why I've been super impressed with the ease-of-use of the [brms](https://cran.r-project.org/web/packages/brms/index.html) package (not to mention Paul's support on GitHub and the Stan Discourse), because getting inferential models to act generatively is pretty clunky and requires custom code to develop good visuals. brms takes care of this for you. To my knowledge, there's no Python equivalent so we'll flip back and forth depending on how far we are in the prototyping stage.\n\nMy favourite book right now is Richard McElreath's [\"Statistical Rethinking\"](https://xcelab.net/rm/statistical-rethinking/), and his accompanying [YouTube](https://www.youtube.com/watch?v=FdnMWdICdRs&list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus) series which are both incredibly well written / produced, and are great discussions of challenges with asking the \"oracle\" of regression seemingly innocuous questions (see the height ~ $alpha$ + $\\beta_{\\text{left leg}}$ $\\text{left leg})$ + $\\beta_{\\text{right leg}}$ $\\text{right leg}$ model for a great example).\n\nI believe that there's huge value in modeling data hierarchially, where groups of individuals are drawn from a population and we'd like to have information flow between them, but these models are often slow, [hard](https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html) to fit, and are usually much harder to set up than conventional non-hierarchical models. I'm hoping to have a repository that acts as a bridge between the different languages, and packages, so that we can all benefit from the massive amount of documentation and knowledge that has already been shared.\n\nI may make errors, if you see one, please email [kiran.gauthier@columbia.edu](mailto:kiran.gauthier@columbia.edu) me or leave a comment and I'll revise it!\n\n## Library\n\nI'll fill this later.\n\n### Other blogs I read\n\nGelman\nBetancourt\nFrank Harrell\nAki Vehtari\n\n### Posts to come\n\nBridgeStan\nSimpson's paradox\nBonferroni correction\nTalking about interactions\n\nWish list item: see how information flows between parameters, include something about synthetic data generation.\n\nAdd draft: true to the document options if youâ€™d like a post to not be included in the listing, site map, or site search. For example:\n#---\ntitle: \"My Post\"\ndescription: \"Post description\"\nauthor: \"Fizz McPhee\"\ndate: \"5/22/2021\"\ndraft: true\n#---\n\n## fill out the about.qmd next with a photo\n\ndate-modified: \"5/23/2021\"\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.552","theme":"cosmo","title":"hierarchy","author":"Kiran Gauthier","listing":{"contents":"posts","sort":"date desc","type":"default","categories":true,"sort-ui":false,"filter-ui":false},"page-layout":"full","title-block-banner":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}