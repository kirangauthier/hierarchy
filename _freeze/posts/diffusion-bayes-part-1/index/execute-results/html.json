{
  "hash": "9b25abaddd2d298788dfb06fe349dc0d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: '`diffusionBayes` - part 1: simulated analysis of single trajectories'\nauthor: Kiran Gauthier\ndate: '2024-05-30'\ncategories:\n  - Python\n  - Brownian motion\n  - diffusion\n  - simulated data\nimage: assets/brownian-nano.gif\n---\n\n# [`diffusionBayes`](https://github.com/kirangauthier/diffusionBayes)\n## Part 1 - Simulating and analyzing individual trajectories\n\nWelcome to the first post in a multi-post series about analyzing diffusive particles trajectories to infer their uncertain diffusivities. All of the code for this project can be found by clicking the link in the titile of this post that'll take you to the project repository.\n\nI'm a firm believer that good inference is enabled by becoming familiar with the data generating process as a way to (1) validate your ability to recover, \"true\", hidden parameters, and (2) see how our models might fail to capture relevant features within the observed data.\n\nThis first post will consider simulated 2-dimensional random walkers with no directional preference (isotropic), which are perfectly well resolved by our camera, or observer, and are built into our `simulate` class. We'll build in complexity as we go, including the opportunity for our particles to:\n\n  (1) drift from convective flows\n  (2) get \"stuck\" on the experimental cell, or media (using potential wells)\n  (3) be drawn from different populations, **this one is really cool**\n  (4) have different sub- and super-diffusive behaviours\n\nwe'll use a couple of different inference strategies, in our `infer` class:\n\n  (1) conventional mean squared displacement analysis\n  (2) a Bayesian analog of the more conventional analysis\n  (3) a population based model, **again, really cool, especially with short, noisy tracks**\n\ndiscriminating between \"good\", and \"bad\" data using posterior predictive checks, in our `check` class:\n\n  (1) mean squared displacement\n  (2) radius of gyration\n  (3) radius of gyration for non-overlapping intervals\n\nwhile modulating some of the experimental parameters, in our `experiment` class:\n\n  (1) artificially reduce the signal-to-noise ratio\n  (2) introduce uncertainty in the centroids of our diffusing particles\n  (3) break up our tracks (because of approximating quasi-3D environment as 2D, or particles fading into background noise)\n  (4) artificially constrain the length of our track **a consequence of above, but this is the most important**\n\nto see how that influences the inference of the diffusivity parameter, $\\widehat{D}$, relative to the true diffusivity, $D_\\text{true}$. When you have long tracks with little uncertainty in the diffusing particle's position, any inference technique will work. But in the presence of short, noisy tracks, we'll demonstrate that the posterior predictive checks and population based model significantly outperforms the conventional techniques in reliably estimating the diffusivities.\n\nFinally, we'll turn it loose on some real, experimental data and see how it performs!\n\n\n## Load libraries\n\n::: {#4b9ee59a .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport matplotlib as mpl\n\nfrom tqdm import tqdm\nfrom scipy import stats\n\nimport session_info\n\n%config InlineBackend.figure_format='retina'\n\nmpl.rc('font',family='Arial')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Arial']\nplt.rcParams['axes.linewidth'] = 0.5\nplt.rc('xtick', labelsize=7)      # fontsize of the tick labels\nplt.rc('ytick', labelsize=7)      # fontsize of the tick labels\n\nplt.rcParams['figure.figsize'] = (4, 3)\nplt.rcParams['font.size'] = 6\n\n%load_ext autoreload\n%autoreload 2\n```\n:::\n\n\n\n## Classes and notation\n\nIn order to make the code as reproducible as possible, I wanted to initialize some classes so that once everything is built out, you can initialize the class, call the method that you want to `simulate`, `infer`, `check`, or `plot`, change the parameters of the `experiment` around, and see how that impacts our results.\n\nWe're going to start with `simulate`, and write some of the simplest `infer` and `plot` functions for an idealized experiment.\n\n::: {#3754be33 .cell execution_count=4}\n``` {.python .cell-code}\nclass Simulate:\n    \"\"\"\n    A class for simulating diffusion processes.\n\n    Methods:\n        generate_brownianMotion: Generates a single isotropic 2D particle trajectory.\n    \"\"\"\n\n    def __init__(self):\n        pass\n```\n:::\n\n\n### Notation\n\nLet's set out some notation to take forward, the 2D trajectory of the $j$-th particle in the $i$-th experiment will be summarized by $\\mathbf{X}_{ij}$, where the coordinates of the $k$-th time point are $\\[x_{ijk}, y_{ijk}\\]$ respectively. The entire trajectory is then given by\n\n$$\nX_{ij} = \\begin{bmatrix}\nx_{ij1} & y_{ij1} \\\\\nx_{ij2} & y_{ij2} \\\\\n\\vdots & \\vdots \\\\\nx_{ijk} & y_{ijk}\n\\end{bmatrix}\n$$\n\nThe reason why it's useful to do it this way is that our diffusive particles are often captured for varying lengths of time, or numbers of frames, so $n_k$, the total number of frames observed for the $k$-th particle varies and prevents us from using a nice `numpy.array()` to contain all of our trajectories.\n\nInstead, we'll use a ragged array, or list of lists structure. All of our functions will accept a single 2D trajectory $\\mathbf{X}_{ij}$ which contains all of the tracked data for that particle alone. Luckily, a lot of the models that we're working with are conjugate (more on this below) or easy enough to work with that it doesn't pose a big issue. We can always decorate our code with an `@jit` from **numba** or leverage **JAX** if we need to speed things up.\n\n### Units and seeding\n\nWe'll compute everything under the hood in units of pixels and frames, for example, the units of diffusivity would be $\\text{px}^2 / \\text{frame}$ under the hood, but will be converted to say $\\mu \\text{m}^2 / s$ by setting an argument like `return_real_units=True`.\n\nIn terms of reproducibility, it's also super important to consider the seeding of each of these functions. You'll see an argument called `base_seed` which ensures that whenever we're sampling random numbers, we can preserve them from run to run.\n\n### Initialize `simulate` class\n\nLet's initialize our classes, starting with `simulate`. All of the functions in these posts will be contained in files that are named by the class, so in this case it'll be `simulate.py`. You can find the file [here](https://github.com/kirangauthier/diffusionBayes).\n\nIn the simplest case, our particles will perform 2D random walks, and I'm going to get a bit loose with the notation we just set forth to help things not get too cluttered too early. Wherever I say $\\mathbf{X}_k$ I really mean $\\mathbf{X}_{ijk}$ so the $k$-th time point of the $j$-th particle in experiment $i$ is just the $k$-th time point. This doesn't butcher our interpretation too badly because our particle's motion is assumed to be uncorrelated with eachother, and you'll see why removing the $i$ and $j$ subscripts helps below.\n\nWe can express the likelihood of sequential steps $\\mathbf{X}_{k-1} = [x_{k-1}, y_{k-1}]$ and $\\mathbf{X}_k$, during a given time interval $\\tau_k = t_k - t_{k-1}$ as:\n\n$$\np(\\mathbf{X}_k \\mid \\mathbf{X}_{k-1}, D, \\tau_k) = \\frac{1}{\\sqrt{4 \\pi D \\tau_k}} \\exp{\\left(- \\frac{r_k^2}{4 D \\tau_k} \\right)}\n$$\n\nwhere $r_k^2 = (x_k - x_{k-1})^2 + (y_k - y_{k-1})^2$ is the 2D displacement of the particle during the time interval $\\tau_k$. If you feel comfortable with the above equation, feel free to skip to the next paragraph, otherwise, read the dropdown note and I'll tell you how I would make sense of the above because I want everyone to stay on board and engaged for as long as they can.\n\n::: {.callout-note collapse=\"true\"}\n*Note:* When we express probabilities, such as $p(\\mathbf{X}_k \\mid \\mathbf{X}_{k-1}, D, \\tau_k)$, variables on the right side of the line (in this case $\\mathbf{X}_{k-1}, D, \\tau_k$) are assumed to be known. Some people or textbooks might say that we're *conditioning* on these variables, all that means is that we're forming our opinion of our unknowns given the things on the right side of the line. So what do we not know? Whatever's on the left side of the line, in this case it's $\\mathbf{X}_k$. Some people might call the variables on the left side of the line random, or latent, variables. All that means is that we don't know their values with certainty. So I would read this as \"conditional on our previous position $\\mathbf{X}_{k-1}$, the diffusivity of our particle $D$, and time lag $\\tau_k$, the likelihoood of the current position of our particle $\\mathbf{X}_k$ is given by the probability density $\\frac{1}{\\sqrt{4 \\pi D \\tau_k}} \\exp{\\left(- \\frac{r_k^2}{4 D \\tau_k} \\right)}$\".\n:::\n\nCool, let's keep going. Now that we've considered a single jump between two time points, the rest of the trajectory is pretty simple because in this model, all displacements are assumed to be uncorrelated.\n\n$$\np(\\mathbf{X}_k \\mid D, \\tau_k) = p(\\mathbf{X}_0) \\prod_{k=1}^K \\frac{1}{4\\pi D \\tau_k} \\exp \\left( -\\frac{r_k^2}{4D \\tau_k} \\right)\n$$\n\nwhere the only new thing I've added is the probability of the initial starting point of the particle, $\\mathbf{X}_0$, which is assumed to be uniform across the viewing area.\n\n#### Brownian motion\n\nCool, so each displacement in 2D is assumed to have variance $4 D \\tau_k$, which is the sum of independent displacements of $2 D \\tau_k$ in each direction, let's implement this below and drop it into our `simulate.py` file. Expand the below notes on alternatives to this implementation\n\n::: {#5cd9cc9d .cell execution_count=5}\n``` {.python .cell-code}\ndef generate_brownianMotion(D, n_steps, X_start, tau, base_seed):\n    \"\"\"\n    Generate a single isotropic 2D particle trajectory.\n\n    Parameters:\n    - D (float): Diffusion coefficient [px^2 / frame]\n    - n_steps (int): Number of steps in the trajectory [frame]\n    - X_start (tuple): Position at time 0 (x, y) [px, px]\n    - tau (float): Time step [frame]\n    - base_seed (int): Random seed for this trajectory\n\n    Returns:\n    - x, y: Arrays containing the x and y positions of the trajectory [px]\n\n    Note:\n    This function uses a independent Gaussian steps to simulate Brownian motion.\n    The x and y dimensions are assumed to be independent.\n    \"\"\"\n\n    np.random.seed(base_seed)\n\n    x = np.zeros(n_steps)\n    y = np.zeros(n_steps)\n\n    x[0], y[0] = X_start\n\n    for k in range(1, n_steps):\n      std_dev = np.sqrt(2 * D * tau)\n      x[k] = x[k-1] + np.random.normal(0, std_dev)\n      y[k] = y[k-1] + np.random.normal(0, std_dev)\n\n    return x, y\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n*Getting fancy:* We could also have written the `generate_brownianMotion()` function as if it were generated from a multivariate Gaussian of variance $4 D \\tau_k$, the results will be the same:\n\n```\ndef generate_brownianMotion(D, n_steps, X_start, tau, base_seed):\n  # ...\n  np.random.seed(base_seed)\n  x = np.zeros(n_steps)\n  y = np.zeros(n_steps)\n\n  x[0], y[0] = X_start\n\n  # Define the covariance matrix for the multivariate Gaussian\n  covariance_matrix = [[4*D*tau, 0], [0, 4*D*tau]]  # Independent x and y with variance 4Dtau respectively\n\n  for k in range(1, n_steps):\n      step = np.random.multivariate_normal([0, 0], covariance_matrix)\n      x[k] = x[k-1] + step[0]\n      y[k] = y[k-1] + step[1]\n\n  return x, y\n```\n:::\n\n::: {.callout-tip collapse=\"true\"}\nFor the sake of efficiency however, you'll see that the final implementation takes advantage of the independence of all jumps and instead computes all of the displacements at once, taking the cumulative sum of their displacements.\n```\n  x[0], y[0] = X_start\n\n  x_traj = np.random.normal(loc=0, scale=2*D*tau, size=t.shape[0]-1)\n  y_traj = np.random.normal(loc=0, scale=2*D*tau, size=t.shape[0]-1)\n\n  x[1:] = x[0] + np.cumsum(x_traj)\n  y[1:] = y[0] + np.cumsum(y_traj)\n\n  return x, y\n```\n:::\n\nLet's visualize the trajectory!\n\n::: {#583af60c .cell execution_count=6}\n``` {.python .cell-code}\nx, y = generate_brownianMotion(D=0.1, n_steps=300, X_start=(0, 0), tau=1, base_seed=4444)\n\nplt.figure(figsize=(4, 3))\nplt.plot(x, y, color=firebrick4)\nplt.axis('equal')\nplt.xticks([0, -5, -10, -15])\nplt.yticks([0, -5, -10, -15])\nplt.xlabel('x [px]')\nplt.ylabel('y [px]')\npass\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=355 height=272}\n:::\n:::\n\n\nLooks great.\n\n### Initialize `infer` class\n\nIn this case, we know exactly what the true diffusion coefficient, $D_\\text{true}$ is because we set it to 1 $\\text{px}^2 / \\text{frame}$. Let's see if we can recover it, and also add our first couple of functions to our `infer` and `plot` classes.\n\n### Conventional MSD analysis\n\nAs we said, we have single particle trajectories in our list of lists, and we want to highlight how short tracks of diffusing particles can be inferred reliably using a hierarchical Bayesian model. At the moment though, we have a really long, perfectly resolved track, so the conventional analysis should be just fine. Remember we have our single particle trajectory, $\\mathbf{X}_k = [x_k, y_k]$ where again I've dropped the $i$ and $j$ indices to help with clutter. The mean squared displacement (MSD) of a particle during a time lag $\\tau$, $\\text{msd}(\\tau)$ evolves linearly in the case of Brownian diffusion, $\\text{msd}(\\tau) = 4 D \\tau$ (in $2\\text{D}$). For arbitrary $\\tau$, the MSD is calculated by:\n\n$$\n\\text{msd}(\\tau) = \\frac{1}{N-\\tau} \\sum_{k=1}^{N-\\tau} [(x_{k + \\tau} - x_k)^2 + (y_{k + \\tau} - y_k)^2]\n$$\n\nSo all it takes is for us to plot the $\\text{msd}$ for various values of $\\tau$ to a line to estimate the value $\\widehat{D}$ (if you're curious why my $D$ is wearing a hat, click below).\n\n:::{callout-tip collapse=\"true\"}\nBecause we usually don't know the true value of a parameter, you'll see me write it's estimate with a hat, as in $\\widehat{D}$ to tell you that it's being fit from the data. This is in constrast to the true value that we had set up earlier in the simualtion, $D_\\text{true}$, which has no hat.\n:::\n\nAs $\\tau$ gets larger and larger, we'll have less and less data to compute the mean displacement of our particle. To be safe in our averaging, we'll only use lags from the first 1/3 of the trajectory.\n\n::: {#e02937f5 .cell execution_count=7}\n``` {.python .cell-code}\ndef calculate_msd(trajectory):\n  x, y = trajectory\n  t = np.arange(len(x))\n  lags = np.unique(t // 3).astype(int)[::2]\n\n  msd = np.zeros((lags.shape[0], ))\n  for i, lag in enumerate(lags):\n    dxlag = np.diff(x[::lag])\n    dylag = np.diff(y[::lag])\n    J = dxlag.shape[0]\n\n    if J == 1:\n      continue\n    else:\n      msd[i] = np.sum( (dxlag - dxlag.mean())**2 + (dylag - dylag.mean())**2 ) / J\n\n  return msd\n\n# def fit_msd(trajectory):\n```\n:::\n\n\n### Conjugate inverse Gamma analysis\n\n::: {#28641c45 .cell execution_count=8}\n``` {.python .cell-code}\ndef infer_diffusivity(trajectory, inference_step=1, drift=True):\n  x, y = trajectory\n\n  ## compute displacements\n  idx = (np.mod(t, inference_step)==0)\n  dt = t[idx][1:] - t[idx][0:-1]\n  dx = x[idx][1:] - x[idx][0:-1]\n  dy = y[idx][1:] - y[idx][0:-1]\n\n  K = dx.shape[0]\n\n  ## estimate drift parameters\n  if drift:\n    Uhat = np.sum(dx) / np.sum(dt)\n    Vhat = np.sum(dy) / np.sum(dt)\n\n    alpha = K - 2\n    beta = np.sum(( (dx - Uhat*dt)**2 + (dy - Vhat*dt)**2 ) / (4*dt))\n\n  ## compute posterior parameters for inverse gamma distribution\n  else:\n    alpha = K - 1\n    beta = np.sum( (dx**2 + dy**2) / (4*dt) )\n\n  return alpha, beta\n\ndef invGamma_toDiffusivity(alpha, beta, mode=True, point_estimate=False, interval=0.05):\n  ## return the mode\n  if mode and point_estimate:\n    mode = beta / (alpha + 1)\n    return mode\n\n  ## return the mean\n  if mode==False and point_estimate:\n    mean = beta / (alpha - 1) ## give an error if alpha not > 1\n    return mean\n\n  if mode and point_estimate==False:\n    mode = beta / (alpha + 1)\n\n    lower = scipy.stats.invgamma.ppf(interval / 2, a=alpha, scale=beta)\n    upper = scipy.stats.invgamma.ppf((1-interval)/2, a=alpha, scale=beta)\n\n    return mode, lower, upper\n```\n:::\n\n\n::: {#cell-fig-polar .cell execution_count=9}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'}\n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![A line plot on a polar axis](index_files/figure-html/fig-polar-output-1.png){#fig-polar width=292 height=287}\n:::\n:::\n\n\n## Citations\n\nThumbnail photo from [Donna Patterson](https://www.nsf.gov/news/mmg/media/images/PalmerStation_chinstrap-penguins_photoby_DonnaPatterson.jpg) hosted on the NSF website.\n\n\n## Session info\n\n::: {#36bd145e .cell execution_count=11}\n``` {.python .cell-code}\nsession_info.show()\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<details>\n<summary>Click to view session information</summary>\n<pre>\n-----\nmatplotlib          3.8.4\nnumpy               1.26.4\nscipy               1.13.0\nsession_info        1.0.0\nsimulate            NA\ntqdm                4.66.4\n-----\n</pre>\n<details>\n<summary>Click to view modules imported as dependencies</summary>\n<pre>\nPIL                         10.3.0\nanyio                       NA\nappnope                     0.1.3\nasttokens                   NA\nattr                        23.1.0\nattrs                       23.1.0\nbabel                       2.11.0\nbrotli                      1.0.9\ncertifi                     2024.02.02\ncffi                        1.16.0\ncharset_normalizer          2.0.4\ncolorama                    0.4.6\ncomm                        0.2.1\ncycler                      0.10.0\ncython_runtime              NA\ndateutil                    2.8.2\ndebugpy                     1.6.7\ndecorator                   5.1.1\ndefusedxml                  0.7.1\nexecuting                   0.8.3\nfastjsonschema              NA\nidna                        3.7\nipykernel                   6.28.0\njedi                        0.18.1\njinja2                      3.1.3\njson5                       NA\njsonschema                  4.19.2\njsonschema_specifications   NA\njupyter_events              0.8.0\njupyter_server              2.10.0\njupyterlab_server           2.25.1\nkiwisolver                  1.4.4\nmarkupsafe                  2.1.3\nmatplotlib_inline           0.1.6\nmpl_toolkits                NA\nnbformat                    5.9.2\noverrides                   NA\npackaging                   23.2\npandas                      2.2.2\nparso                       0.8.3\npexpect                     4.8.0\npkg_resources               NA\nplatformdirs                3.10.0\nprometheus_client           NA\nprompt_toolkit              3.0.43\npsutil                      5.9.0\nptyprocess                  0.7.0\npure_eval                   0.2.2\npydev_ipython               NA\npydevconsole                NA\npydevd                      2.9.5\npydevd_file_utils           NA\npydevd_plugins              NA\npydevd_tracing              NA\npygments                    2.15.1\npyparsing                   3.0.9\npythonjsonlogger            NA\npytz                        2024.1\nreferencing                 NA\nrequests                    2.31.0\nrfc3339_validator           0.1.4\nrfc3986_validator           0.1.1\nrpds                        NA\nsend2trash                  NA\nsix                         1.16.0\nsniffio                     1.3.0\nsocks                       1.7.1\nstack_data                  0.2.0\ntornado                     6.3.3\ntraitlets                   5.7.1\nunicodedata2                NA\nurllib3                     2.2.1\nwcwidth                     0.2.5\nwebsocket                   1.8.0\nyaml                        6.0.1\nzmq                         25.1.2\n</pre>\n</details> <!-- seems like this ends pre, so might as well be explicit -->\n<pre>\n-----\nIPython             8.20.0\njupyter_client      8.6.0\njupyter_core        5.5.0\njupyterlab          4.0.11\nnotebook            7.0.8\n-----\nPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:54:21) [Clang 16.0.6 ]\nmacOS-13.6.1-arm64-arm-64bit\n-----\nSession information updated at 2024-08-02 15:24\n</pre>\n</details>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}